{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 616,
     "status": "ok",
     "timestamp": 1742750052664,
     "user": {
      "displayName": "Jad Al-Jawhari",
      "userId": "14646573670663752225"
     },
     "user_tz": 240
    },
    "id": "_KZEs1t1h61c",
    "outputId": "c55bc312-11a4-456f-bcbe-5b6a59be5281"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4382,
     "status": "ok",
     "timestamp": 1742750057048,
     "user": {
      "displayName": "Jad Al-Jawhari",
      "userId": "14646573670663752225"
     },
     "user_tz": 240
    },
    "id": "vyiuGqb1-qKA",
    "outputId": "cd2bd231-fe33-4140-a5a7-e833de0a77ee"
   },
   "outputs": [],
   "source": [
    "!pip install unidecode\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lv7ewfUs-qm3"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:128,expandable_segments:True\"\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\n",
    "from unidecode import unidecode\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2CJM5rhM-uib"
   },
   "outputs": [],
   "source": [
    "# Tensor folders\n",
    "BASE_DIR = r\"/content/drive/MyDrive/APS360_Project\"\n",
    "TRAIN_TENSOR_FOLDER = os.path.join(BASE_DIR, \"combined_tensors_train\")\n",
    "VAL_TENSOR_FOLDER   = os.path.join(BASE_DIR, \"combined_tensors_val\")\n",
    "TEST_TENSOR_FOLDER  = os.path.join(BASE_DIR, \"combined_tensors_test\")\n",
    "\n",
    "!cp \"/content/drive/MyDrive/APS360_Project/final_train_metadata.csv\" /tmp/\n",
    "!cp \"/content/drive/MyDrive/APS360_Project/final_val_metadata.csv\" /tmp/\n",
    "!cp \"/content/drive/MyDrive/APS360_Project/final_test_metadata.csv\" /tmp/\n",
    "\n",
    "# Update CSV paths to point to local copies\n",
    "TRAIN_METADATA = \"/tmp/final_train_metadata.csv\"\n",
    "VAL_METADATA   = \"/tmp/final_val_metadata.csv\"\n",
    "TEST_METADATA  = \"/tmp/final_test_metadata.csv\"\n",
    "\n",
    "CHECKPOINT_PATH = os.path.join(BASE_DIR, \"BestModelCheckpoint.pth\")\n",
    "\n",
    "INPUT_SIZE  = 39\n",
    "OUTPUT_SIZE = 11\n",
    "BATCH_SIZE  = 4\n",
    "PATIENCE    = 3\n",
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wZFauGN7-v2b"
   },
   "outputs": [],
   "source": [
    "# Collate function to process a batch of data\n",
    "def collate(batch):\n",
    "    if DEBUG:\n",
    "        print(\"[collate] Received a batch of size:\", len(batch))\n",
    "\n",
    "    # Separate tensors and labels, convert tensors to float and ensure they are contiguous\n",
    "    tensors, labels = zip(*batch)\n",
    "    tensors = [tensor.float().contiguous() for tensor in tensors]\n",
    "\n",
    "    # Pad tensors to the same length and stack labels into a tensor\n",
    "    padded_tensors = pad_sequence(tensors, batch_first=True, padding_value=0)\n",
    "    labels = torch.stack(labels, dim=0)\n",
    "\n",
    "    # Get original sequence lengths and pack the padded tensors\n",
    "    sequence_lengths = torch.tensor([len(tensor) for tensor in tensors], dtype=torch.long)\n",
    "    if DEBUG:\n",
    "        print(\"[collate] Padded tensors shape:\", padded_tensors.shape)\n",
    "        print(\"[collate] Sequence lengths:\", sequence_lengths.tolist())\n",
    "    packed_input = pack_padded_sequence(\n",
    "        padded_tensors,\n",
    "        sequence_lengths,\n",
    "        batch_first=True,\n",
    "        enforce_sorted=False\n",
    "    )\n",
    "\n",
    "    # Ensure the packed data is contiguous\n",
    "    if not packed_input.data.is_contiguous():\n",
    "        packed_input = torch.nn.utils.rnn.PackedSequence(\n",
    "            packed_input.data.contiguous(),\n",
    "            packed_input.batch_sizes,\n",
    "            packed_input.sorted_indices,\n",
    "            packed_input.unsorted_indices\n",
    "        )\n",
    "\n",
    "    if DEBUG:\n",
    "        print(\"[collate] Returning packed_input and labels.\\n\")\n",
    "    return packed_input, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BYuOBtxB-zGx"
   },
   "outputs": [],
   "source": [
    "class TensorDataset(Dataset):\n",
    "    def __init__(self, tensor_folder, metadata_csv):\n",
    "        # Initialize dataset (load metadata and list tensor files.)\n",
    "        if DEBUG:\n",
    "            print(f\"\\n[TensorDataset] Initializing dataset for folder: {tensor_folder}\")\n",
    "        self.tensor_folder = tensor_folder\n",
    "\n",
    "        if DEBUG:\n",
    "            print(f\"[TensorDataset] Reading metadata from {metadata_csv}\")\n",
    "        self.df = pd.read_csv(metadata_csv)\n",
    "        self.df[self.df.columns[0]] = self.df[self.df.columns[0]].apply(unidecode)\n",
    "        self.file_list = os.listdir(tensor_folder)\n",
    "        if DEBUG:\n",
    "            print(f\"[TensorDataset] Found {len(self.file_list)} files on disk.\")\n",
    "        self.matching_df = self.df[self.df[self.df.columns[0]].isin(self.file_list)].copy()\n",
    "        self.matching_df.sort_values(by=self.matching_df.columns[0], inplace=True)\n",
    "        self.labels = self.matching_df.iloc[:, 1:].values\n",
    "        self.filenames = self.matching_df[self.df.columns[0]].tolist()\n",
    "        if DEBUG:\n",
    "            print(f\"[TensorDataset] Dataset initialization complete. Total items: {len(self.filenames)}\\n\")\n",
    "\n",
    "    def _rename_files(self):\n",
    "        # Rename files to normalized names.\n",
    "        fails = []\n",
    "        for file in os.listdir(self.tensor_folder):\n",
    "            normalized_name = unidecode(file)\n",
    "            if file != normalized_name:\n",
    "                old_file_path = os.path.join(self.tensor_folder, file)\n",
    "                new_file_path = os.path.join(self.tensor_folder, normalized_name)\n",
    "                if os.path.exists(old_file_path):\n",
    "                    try:\n",
    "                        os.rename(old_file_path, new_file_path)\n",
    "                        if DEBUG:\n",
    "                            print(f\"[TensorDataset] Renamed: {file} -> {normalized_name}\")\n",
    "                    except Exception as e:\n",
    "                        if DEBUG:\n",
    "                            print(f\"[TensorDataset] Error renaming {file}: {e}\")\n",
    "                        fails.append((file, str(e)))\n",
    "                else:\n",
    "                    if DEBUG:\n",
    "                        print(f\"[TensorDataset] File not found, skipping: {file}\")\n",
    "                    fails.append((file, \"File not found\"))\n",
    "        if fails and DEBUG:\n",
    "            print(\"\\n[TensorDataset] Failed renames in folder:\", self.tensor_folder)\n",
    "            for f in fails:\n",
    "                print(f\"  - {f}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return total number of items in the dataset.\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load and return the tensor and corresponding label for the given index.\n",
    "        fname = self.filenames[idx]\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "        tensor_path = os.path.join(self.tensor_folder, fname)\n",
    "        data_array = np.load(tensor_path, mmap_mode='r')\n",
    "        tensor = torch.tensor(data_array, dtype=torch.float32).contiguous()\n",
    "        if tensor.shape[0] > MAX_SEQ_LEN:\n",
    "            tensor = tensor[:MAX_SEQ_LEN, :]\n",
    "        if DEBUG and idx % 50 == 0:\n",
    "            print(f\"[TensorDataset] Loading item {idx}: {fname} with shape {tensor.shape}\")\n",
    "        return tensor, label\n",
    "\n",
    "def create_data_loader(tensor_folder, metadata_csv, batch_size=BATCH_SIZE, shuffle=False):\n",
    "    # Create and return a DataLoader for the TensorDataset.\n",
    "    if DEBUG:\n",
    "        print(f\"\\n[create_data_loader] Creating DataLoader for folder: {tensor_folder}\")\n",
    "    dataset = TensorDataset(tensor_folder, metadata_csv)\n",
    "    loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "        collate_fn=collate\n",
    "    )\n",
    "    if DEBUG:\n",
    "        print(f\"[create_data_loader] DataLoader created with {len(dataset)} samples and batch_size={batch_size}.\\n\")\n",
    "    return loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9s6e7MC--3hj"
   },
   "outputs": [],
   "source": [
    "class MusicGRU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=256, output_size=OUTPUT_SIZE, num_layers=5, dropout=0.3):\n",
    "        super(MusicGRU, self).__init__()\n",
    "        if DEBUG:\n",
    "            print(f\"[MusicGRU] Initializing MusicGRU with input_size={input_size}, hidden_size={hidden_size}, \"\n",
    "                  f\"output_size={output_size}, num_layers={num_layers}, dropout={dropout}.\")\n",
    "        # Initialize GRU, normalization, and output layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.layer_norm = nn.LayerNorm(hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if DEBUG:\n",
    "            print(\"[MusicGRU.forward] Forward pass started.\")\n",
    "        # Processes input as a PackedSequence if this part is required\n",
    "        if isinstance(x, torch.nn.utils.rnn.PackedSequence):\n",
    "            if not x.data.is_contiguous():\n",
    "                if DEBUG:\n",
    "                    print(\"[MusicGRU.forward] Making PackedSequence data contiguous.\")\n",
    "                x = torch.nn.utils.rnn.PackedSequence(\n",
    "                    x.data.contiguous(),\n",
    "                    x.batch_sizes,\n",
    "                    x.sorted_indices,\n",
    "                    x.unsorted_indices\n",
    "                )\n",
    "            self.gru.flatten_parameters()\n",
    "            try:\n",
    "                _, hidden = self.gru(x)\n",
    "            except RuntimeError as e:\n",
    "                if DEBUG:\n",
    "                    print(\"RuntimeError in GRU with PackedSequence. Disabling cuDNN for this call.\")\n",
    "                with torch.backends.cudnn.flags(enabled=False):\n",
    "                    _, hidden = self.gru(x)\n",
    "            out = hidden[-1]\n",
    "        else:\n",
    "            if DEBUG:\n",
    "                print(\"[MusicGRU.forward] Input is not a PackedSequence.\")\n",
    "            if not x.is_contiguous():\n",
    "                if DEBUG:\n",
    "                    print(\"[MusicGRU.forward] Making tensor data contiguous.\")\n",
    "                x = x.contiguous()\n",
    "            x = x.float()\n",
    "            self.gru.flatten_parameters()\n",
    "            device = x.device\n",
    "            h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "            try:\n",
    "                out, _ = self.gru(x, h0)\n",
    "            except RuntimeError as e:\n",
    "                if DEBUG:\n",
    "                    print(\"RuntimeError in GRU with non-packed input. Disabling cuDNN for this call.\")\n",
    "                with torch.backends.cudnn.flags(enabled=False):\n",
    "                    out, _ = self.gru(x, h0)\n",
    "            out = out[:, -1, :]\n",
    "        # Normalize and apply final linear transformation\n",
    "        out = self.layer_norm(out)\n",
    "        out = self.fc(out)\n",
    "        if DEBUG:\n",
    "            print(\"[MusicGRU.forward] Forward pass complete.\\n\")\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Wk_H9-q-6Ms"
   },
   "outputs": [],
   "source": [
    "# Training & Evaluation Functions (with Early Stopping)\n",
    "\n",
    "def train_and_evaluate_model(model, train_loader, val_loader, num_epochs=15, learning_rate=0.001, patience=3):\n",
    "    # Setup device, loss, optimizer, and mixed-precision scaler\n",
    "    print(\"[train_and_evaluate_model] Starting training...\")\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"[train_and_evaluate_model] Using device: {device}\")\n",
    "    model.to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "    # Load checkpoint if available\n",
    "    if os.path.exists(CHECKPOINT_PATH):\n",
    "        print(f\"[train_and_evaluate_model] Loading checkpoint from {CHECKPOINT_PATH}...\")\n",
    "        checkpoint = torch.load(CHECKPOINT_PATH, map_location=device)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        best_val_loss = checkpoint['best_val_loss']\n",
    "        print(f\"[train_and_evaluate_model] Checkpoint loaded! Resuming from epoch {start_epoch} with best_val_loss = {best_val_loss:.4f}\\n\")\n",
    "    else:\n",
    "        start_epoch = 0\n",
    "        best_val_loss = float('inf')\n",
    "        print(\"[train_and_evaluate_model] No checkpoint found. Starting training from scratch.\\n\")\n",
    "\n",
    "    train_losses, val_losses = [], []\n",
    "    training_start_time = time.time()\n",
    "    last_time_log = training_start_time\n",
    "    wait = 0  # Early stopping counter\n",
    "\n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        print(f\"\\n[train_and_evaluate_model] Epoch {epoch+1}/{num_epochs} - Training Phase\")\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "\n",
    "        for batch_idx, (songs, labels) in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch+1} Training\")):\n",
    "            current_time = time.time()\n",
    "            if current_time - last_time_log >= 300:\n",
    "                elapsed = current_time - training_start_time\n",
    "                print(f\"[train_and_evaluate_model] Time elapsed so far: {elapsed/60:.2f} minutes\")\n",
    "                last_time_log = current_time\n",
    "\n",
    "            songs, labels = songs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            with torch.cuda.amp.autocast():\n",
    "                outputs = model(songs)\n",
    "                loss = criterion(outputs, labels)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "        print(f\"[train_and_evaluate_model] Epoch {epoch+1} - Training Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "        print(f\"[train_and_evaluate_model] Epoch {epoch+1}/{num_epochs} - Validation Phase\")\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        for batch_idx, (songs, labels) in enumerate(tqdm(val_loader, desc=f\"Epoch {epoch+1} Validation\")):\n",
    "            songs, labels = songs.to(device), labels.to(device)\n",
    "            with torch.cuda.amp.autocast():\n",
    "                outputs = model(songs)\n",
    "                loss = criterion(outputs, labels)\n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        print(f\"[train_and_evaluate_model] Epoch {epoch+1} - Validation Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "        # Save checkpoint if validation improves; else, update early stopping counter\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            wait = 0\n",
    "            checkpoint = {\n",
    "                'epoch': epoch + 1,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'best_val_loss': best_val_loss,\n",
    "            }\n",
    "            torch.save(checkpoint, CHECKPOINT_PATH)\n",
    "            print(f\"[train_and_evaluate_model] New best model found! Saving checkpoint at epoch {epoch+1}\")\n",
    "        else:\n",
    "            wait += 1\n",
    "            print(f\"[train_and_evaluate_model] No improvement in validation loss at epoch {epoch+1}. Wait count: {wait}/{patience}\")\n",
    "            if wait >= patience:\n",
    "                print(\"[train_and_evaluate_model] Early stopping triggered!\")\n",
    "                break\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # Plot training and validation loss curves\n",
    "    print(\"\\n[train_and_evaluate_model] Training complete. Plotting loss curves...\")\n",
    "    plt.figure()\n",
    "    epochs = list(range(start_epoch + 1, start_epoch + 1 + len(train_losses)))\n",
    "    plt.plot(epochs, train_losses, label='Training Loss')\n",
    "    plt.plot(epochs, val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    print(\"[train_and_evaluate_model] Training and evaluation finished.\\n\")\n",
    "\n",
    "\n",
    "def test_model(model, test_loader):\n",
    "    # Load the best checkpoint and evaluate model performance on test data\n",
    "    print(\"[test_model] Starting testing...\")\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"[test_model] Loading model weights from {CHECKPOINT_PATH}\")\n",
    "    checkpoint = torch.load(CHECKPOINT_PATH, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    predictions, ground_truths = [], []\n",
    "    for batch_idx, (songs, labels) in enumerate(tqdm(test_loader, desc=\"Testing\")):\n",
    "        songs, labels = songs.to(device), labels.to(device)\n",
    "        with torch.cuda.amp.autocast(dtype=torch.float16):\n",
    "            outputs = model(songs)\n",
    "        predictions.append(outputs.detach().cpu())\n",
    "        ground_truths.append(labels.detach().cpu())\n",
    "    predictions = torch.cat(predictions, dim=0).numpy()\n",
    "    ground_truths = torch.cat(ground_truths, dim=0).numpy()\n",
    "    mse = mean_squared_error(ground_truths, predictions)\n",
    "    print(f\"[test_model] Test MSE: {mse:.4f}\\n\")\n",
    "    return predictions, ground_truths, mse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "el_rJ8Rb-_Sf"
   },
   "outputs": [],
   "source": [
    "# Hyperparameter Tuning Experiments\n",
    "def run_experiment(exp_id, hidden_size, learning_rate, dropout):\n",
    "    print(f\"\\n[Experiment {exp_id}] Starting experiment with hidden_size={hidden_size}, learning_rate={learning_rate}, dropout={dropout}\")\n",
    "\n",
    "    # Update checkpoint path per experiment to avoid conflicts\n",
    "    exp_checkpoint = os.path.join(CHECKPOINT_DIR, f\"BestModelCheckpoint_exp{exp_id}.pth\")\n",
    "\n",
    "    # Create DataLoaders\n",
    "    train_loader = create_data_loader(TRAIN_TENSOR_FOLDER, TRAIN_METADATA, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader   = create_data_loader(VAL_TENSOR_FOLDER, VAL_METADATA, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    test_loader  = create_data_loader(TEST_TENSOR_FOLDER, TEST_METADATA, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    # Initialize the model with given hyperparameters\n",
    "    model = MusicGRU(input_size=INPUT_SIZE, hidden_size=hidden_size, output_size=OUTPUT_SIZE, num_layers=5, dropout=dropout)\n",
    "\n",
    "    # Set the global CHECKPOINT_PATH for this experiment\n",
    "    global CHECKPOINT_PATH\n",
    "    CHECKPOINT_PATH = exp_checkpoint\n",
    "\n",
    "    # Train and evaluate the model\n",
    "    train_and_evaluate_model(model, train_loader, val_loader, num_epochs=15, learning_rate=learning_rate, patience=PATIENCE)\n",
    "\n",
    "    # Test the model and return the test MSE\n",
    "    _, _, mse = test_model(model, test_loader)\n",
    "    print(f\"[Experiment {exp_id}] Completed with Test MSE: {mse:.4f}\\n\")\n",
    "    return mse\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 2015896,
     "status": "ok",
     "timestamp": 1742752151053,
     "user": {
      "displayName": "Jad Al-Jawhari",
      "userId": "14646573670663752225"
     },
     "user_tz": 240
    },
    "id": "4Mz5BXx3YZtJ",
    "outputId": "487604d3-1521-485f-ebab-ce12256fbfaf"
   },
   "outputs": [],
   "source": [
    "def run_experiment_3(force_train=True):\n",
    "    exp_id = 3\n",
    "    hidden_size = 256\n",
    "    learning_rate = 0.001\n",
    "    dropout = 0.5\n",
    "    print(f\"\\n[Experiment {exp_id}] Starting experiment with hidden_size={hidden_size}, learning_rate={learning_rate}, dropout={dropout}\")\n",
    "\n",
    "    exp_checkpoint = os.path.join(CHECKPOINT_DIR, f\"BestModelCheckpoint_exp{exp_id}.pth\")\n",
    "    global CHECKPOINT_PATH\n",
    "    CHECKPOINT_PATH = exp_checkpoint\n",
    "    print(f\"[Experiment {exp_id}] Checkpoint path set to: {CHECKPOINT_PATH}\")\n",
    "\n",
    "    print(f\"[Experiment {exp_id}] Creating DataLoaders...\")\n",
    "    train_loader = create_data_loader(TRAIN_TENSOR_FOLDER, TRAIN_METADATA, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader   = create_data_loader(VAL_TENSOR_FOLDER, VAL_METADATA, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    test_loader  = create_data_loader(TEST_TENSOR_FOLDER, TEST_METADATA, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    print(f\"[Experiment {exp_id}] Initializing MusicGRU model...\")\n",
    "    model = MusicGRU(input_size=INPUT_SIZE, hidden_size=hidden_size, output_size=OUTPUT_SIZE, num_layers=5, dropout=dropout)\n",
    "\n",
    "    if os.path.exists(exp_checkpoint):\n",
    "        print(f\"[Experiment {exp_id}] Checkpoint found. Loading checkpoint and resuming training.\")\n",
    "        checkpoint = torch.load(CHECKPOINT_PATH, map_location=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    else:\n",
    "        print(f\"[Experiment {exp_id}] No checkpoint found. Starting training from scratch.\")\n",
    "\n",
    "    # Force training (or resume training) if force_train is True\n",
    "    if force_train:\n",
    "        print(f\"[Experiment {exp_id}] Forcing training to resume (loss curves will be updated).\")\n",
    "        train_and_evaluate_model(model, train_loader, val_loader, num_epochs=15, learning_rate=learning_rate, patience=PATIENCE)\n",
    "    else:\n",
    "        print(f\"[Experiment {exp_id}] Skipping training.\")\n",
    "\n",
    "    print(f\"[Experiment {exp_id}] Testing the model...\")\n",
    "    _, _, mse = test_model(model, test_loader)\n",
    "    print(f\"[Experiment {exp_id}] Completed with Test MSE: {mse:.4f}\\n\")\n",
    "    return mse\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mse_exp3 = run_experiment_3(force_train=True)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
